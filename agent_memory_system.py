# -*- coding: utf-8 -*-


import os
import redis
import numpy as np
import faiss
import json
import sqlite3
from neo4j import GraphDatabase
import uuid
import time
from typing import List, Dict, Any, Optional
import requests
from contextlib import asynccontextmanager # [æ–°å¢] å¯¼å…¥ asynccontextmanager

# --- FastAPI & Pydantic ---
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# --- 0. è¾…åŠ©å·¥å…· ---
class EnhancedJSONEncoder(json.JSONEncoder):
    """ä¸€ä¸ªå¯ä»¥å¤„ç†Numpyæ•°æ®ç±»å‹çš„JSONç¼–ç å™¨"""
    def default(self, o):
        if isinstance(o, np.integer): return int(o)
        if isinstance(o, np.floating): return float(o)
        if isinstance(o, np.ndarray): return o.tolist()
        return super(EnhancedJSONEncoder, self).default(o)

# --- 1. çŸ­æœŸè®°å¿†æ¨¡å— (STM) - ä¼˜åŒ–ç‰ˆï¼šå­˜å‚¨å¯¹è¯æ‘˜è¦ ---
class ShortTermMemory:
    def __init__(self, redis_client, conversation_ttl=1800):
        self.client = redis_client
        self.ttl = conversation_ttl
        print("âœ… çŸ­æœŸè®°å¿†æ¨¡å— (Redis Hashç»“æ„) åˆå§‹åŒ–å®Œæˆã€‚")
    
    def store_summary(self, conversation_id: str, conversation_summary: Dict[str, Any], round_id: int):
        """å­˜å‚¨å¯¹è¯æ‘˜è¦ï¼ˆæ–°æ–¹æ³•ï¼‰- æ¥å—å­—å…¸æ ¼å¼çš„æ‘˜è¦æ•°æ®"""
        # ä»ä¼ å…¥çš„æ‘˜è¦æ•°æ®ä¸­æå–ä¿¡æ¯
        summary_data = {
            "round_id": round_id,
            "user_request": conversation_summary.get('user_request', ''),
            "final_answer": conversation_summary.get('final_answer', ''),
            "memories_used": conversation_summary.get('memories_used', []),
            "timestamp": conversation_summary.get('timestamp', time.time()),
            "conversation_length": conversation_summary.get('conversation_length', 0)
        }
        
        # ä½¿ç”¨Hashç»“æ„å­˜å‚¨ï¼Œå­—æ®µåä¸ºè½®æ¬¡å·
        key = f"stm:conversation:{conversation_id}:summaries"
        self.client.hset(key, f"round_{round_id}", json.dumps(summary_data, cls=EnhancedJSONEncoder))
        self.client.expire(key, self.ttl)
        print(f"ğŸ§  STM: å­˜å‚¨ç¬¬{round_id}è½®å¯¹è¯æ‘˜è¦åˆ° {conversation_id}")
    
    def retrieve_summaries(self, conversation_id: str, last_k: int = 15) -> List[Dict[str, Any]]:
        """æ£€ç´¢å¯¹è¯æ‘˜è¦ï¼ˆæ–°æ–¹æ³•ï¼‰"""
        key = f"stm:conversation:{conversation_id}:summaries"
        all_summaries = self.client.hgetall(key)
        
        if not all_summaries:
            print(f"ğŸ§  STM: å¯¹è¯ {conversation_id} æ— æ‘˜è¦è®°å½•ã€‚")
            return []
        
        # è§£æå¹¶æŒ‰è½®æ¬¡æ’åº
        summaries = []
        for field, data in all_summaries.items():
            try:
                summary = json.loads(data)
                summaries.append(summary)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ STM: è§£ææ‘˜è¦æ•°æ®å¤±è´¥: {e}")
                continue
        
        # æŒ‰è½®æ¬¡å·æ’åºï¼Œè¿”å›æœ€è¿‘çš„Kæ¡
        summaries.sort(key=lambda x: x.get('round_id', x.get('round', 0)))
        result = summaries[-last_k:] if len(summaries) > last_k else summaries
        print(f"ğŸ§  STM: ä»å¯¹è¯ {conversation_id} ä¸­æ£€ç´¢åˆ° {len(result)} æ¡æ‘˜è¦ã€‚")
        return result
    
    # ä¿ç•™åŸæœ‰æ–¹æ³•ä»¥å…¼å®¹æ—§ä»£ç 
    def store(self, conversation_id: str, message: Dict[str, Any]):
        """å­˜å‚¨åŸå§‹æ¶ˆæ¯ï¼ˆå…¼å®¹æ–¹æ³•ï¼‰"""
        key = f"stm:conversation:{conversation_id}"
        self.client.rpush(key, json.dumps(message, cls=EnhancedJSONEncoder))
        self.client.expire(key, self.ttl)
        print(f"ğŸ§  STM: å­˜å‚¨æ¶ˆæ¯åˆ°å¯¹è¯ {conversation_id}")
    
    def retrieve(self, conversation_id: str, last_k: int = 10) -> List[Dict[str, Any]]:
        """æ£€ç´¢åŸå§‹æ¶ˆæ¯ï¼ˆå…¼å®¹æ–¹æ³•ï¼‰"""
        key = f"stm:conversation:{conversation_id}"
        
        # æ£€æŸ¥keyçš„ç±»å‹ - ä¿®å¤decodeé”™è¯¯
        try:
            key_type_bytes = self.client.type(key)
            if key_type_bytes:
                key_type = key_type_bytes.decode('utf-8') if isinstance(key_type_bytes, bytes) else str(key_type_bytes)
            else:
                key_type = 'none'
        except Exception as e:
            print(f"âš ï¸ STM: æ£€æŸ¥keyç±»å‹å¤±è´¥: {e}")
            key_type = 'none'
        
        if key_type == 'string':
            # æ–°æ ¼å¼ï¼šJSONå¯¹è±¡å­˜å‚¨
            data = self.client.get(key)
            if data:
                conv_data = json.loads(data)
                messages = conv_data.get('messages', [])
                print(f"ğŸ§  STM: ä»å¯¹è¯ {conversation_id} ä¸­æ£€ç´¢åˆ° {len(messages)} æ¡æ¶ˆæ¯ã€‚")
                return messages[-last_k:] if messages else []
        elif key_type == 'list':
            # æ—§æ ¼å¼ï¼šlistå­˜å‚¨ï¼ˆå½“å‰ä½¿ç”¨çš„æ ¼å¼ï¼‰
            items = self.client.lrange(key, -last_k, -1)
            print(f"ğŸ§  STM: ä»å¯¹è¯ {conversation_id} ä¸­æ£€ç´¢æœ€è¿‘ {len(items)} æ¡æ¶ˆæ¯ã€‚")
            return [json.loads(item.decode('utf-8') if isinstance(item, bytes) else item) for item in items]
        
        print(f"ğŸ§  STM: å¯¹è¯ {conversation_id} æ— è®°å½•ã€‚")
        return []
    def clear(self, conversation_id: str):
        key = f"stm:conversation:{conversation_id}"; self.client.delete(key)
        print(f"ğŸ—‘ï¸ STM: æ¸…é™¤å¯¹è¯ {conversation_id} çš„çŸ­æœŸè®°å¿†ã€‚")
class WorkingMemory:
    def __init__(self, redis_client):
        self.client = redis_client
        print("âœ… å·¥ä½œè®°å¿†æ¨¡å— (Redis) åˆå§‹åŒ–å®Œæˆã€‚")
    def store(self, agent_id: str, task_id: str, data: Dict[str, Any]):
        key = f"wm:task:{task_id}"; self.client.set(key, json.dumps(data, cls=EnhancedJSONEncoder))
        print(f"ğŸ“ WM: ä¸ºä»»åŠ¡ {task_id} æ›´æ–°å·¥ä½œè®°å¿†ã€‚")
    def retrieve(self, agent_id: str = None, task_id: str = None) -> Optional[Dict[str, Any]]:
        # æ”¯æŒå¤šç§æŸ¥è¯¢æ–¹å¼
        if task_id and not agent_id:
            # ç›´æ¥é€šè¿‡task_idæŸ¥è¯¢
            key = f"wm:task:{task_id}"
            data = self.client.get(key)
            if data:
                print(f"ğŸ“ WM: æ£€ç´¢åˆ°ä»»åŠ¡ {task_id} çš„å·¥ä½œè®°å¿†ã€‚")
                return json.loads(data)
        
        if agent_id and task_id:
            # é€šè¿‡agent_idå’Œtask_idæŸ¥è¯¢
            key = f"wm:task:{task_id}"
            data = self.client.get(key)
            if data:
                print(f"ğŸ“ WM: æ£€ç´¢åˆ°ä»»åŠ¡ {task_id} çš„å·¥ä½œè®°å¿†ã€‚")
                return json.loads(data)
        
        print(f"ğŸ“ WM: æœªæ‰¾åˆ°ä»»åŠ¡ {task_id} çš„å·¥ä½œè®°å¿†ã€‚")
        return None
    def clear(self, agent_id: str, task_id: str):
        key = f"wm:task:{task_id}"; self.client.delete(key)
        print(f"ğŸ—‘ï¸ WM: æ¸…é™¤ä»»åŠ¡ {task_id} çš„å·¥ä½œè®°å¿†ã€‚")
class StructuredLTM:
    def __init__(self, db_path='ltm.db'):
        self.conn = sqlite3.connect(db_path, check_same_thread=False); self.cursor = self.conn.cursor()
        self.cursor.execute("CREATE TABLE IF NOT EXISTS preferences (user_id TEXT, key TEXT, value TEXT, updated_at REAL, PRIMARY KEY (user_id, key))")
        self.conn.commit(); print(f"âœ… ç»“æ„åŒ–é•¿æœŸè®°å¿†æ¨¡å— (SQLite @ {db_path}) åˆå§‹åŒ–å®Œæˆã€‚")
    def store(self, user_id: str, key: str, value: Any):
        # æ·»åŠ æ•°æ®åº“é”å®šé‡è¯•æœºåˆ¶
        max_retries = 5
        for retry in range(max_retries):
            try:
                self.cursor.execute("INSERT OR REPLACE INTO preferences VALUES (?, ?, ?, ?)", (user_id, key, json.dumps(value), time.time()))
                self.conn.commit()
                break
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and retry < max_retries - 1:
                    import time as time_module
                    time_module.sleep(0.1 * (retry + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
                    continue
                else:
                    raise
        print(f"âš™ï¸ LTM: ä¸ºç”¨æˆ· {user_id} å­˜å‚¨åå¥½ '{key}'ã€‚")
    def retrieve(self, user_id: str, key: str) -> Optional[Any]:
        # å…ˆå°è¯•ltm_preferencesè¡¨
        self.cursor.execute("SELECT value FROM ltm_preferences WHERE user_id = ? AND key = ?", (user_id, key))
        row = self.cursor.fetchone()
        if row:
            print(f"âš™ï¸ LTM: æ£€ç´¢åˆ°ç”¨æˆ· {user_id} çš„åå¥½ '{key}'ã€‚")
            # æ•°æ®åº“ä¸­å­˜å‚¨çš„æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›ï¼Œä¸éœ€è¦json.loads
            return row[0]
        
        # å…¼å®¹æ—§è¡¨å
        self.cursor.execute("SELECT value FROM preferences WHERE user_id = ? AND key = ?", (user_id, key))
        row = self.cursor.fetchone()
        if row:
            print(f"âš™ï¸ LTM: æ£€ç´¢åˆ°ç”¨æˆ· {user_id} çš„åå¥½ '{key}'ã€‚")
            return json.loads(row[0])
        
        print(f"âš™ï¸ LTM: æœªæ‰¾åˆ°ç”¨æˆ· {user_id} çš„åå¥½ '{key}'ã€‚")
        return None
class KnowledgeGraphMemory:
    def __init__(self, uri="bolt://localhost:7687", user="neo4j", password="*****"):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        print(f"âœ… çŸ¥è¯†å›¾è°±æ¨¡å— (Neo4j @ {uri}) åˆå§‹åŒ–å®Œæˆã€‚é»˜è®¤ç”¨æˆ·: {user}")

    def store(self, subject: str, relation: str, obj: str):
        with self.driver.session() as session:
            session.run(
                "MERGE (a:Entity {name: $subject}) "
                "MERGE (b:Entity {name: $object}) "
                "MERGE (a)-[r:RELATION {type: $relation}]->(b)",
                subject=subject, relation=relation, object=obj
            )
        print(f"ğŸ•¸ï¸ KG: å­˜å‚¨å…³ç³» '{subject} -[{relation}]-> {obj}'ã€‚")

    def retrieve(self, subject: str, relation: str) -> dict:
        with self.driver.session() as session:
            # ç­–ç•¥1: ç²¾ç¡®åŒ¹é…
            result = session.run(
                "MATCH (a)-[r:RELATION]->(b) WHERE a.name = $subject RETURN a.name as subject, type(r) as relation, b.name as target",
                subject=subject
            )
            records = result.data()
            
            # ç­–ç•¥2: å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
            if not records:
                # æå–å…³é”®è¯è¿›è¡Œæ¨¡ç³ŠæŸ¥è¯¢
                keywords = subject.split()
                for keyword in keywords:
                    if len(keyword) > 1:  # è·³è¿‡å¤ªçŸ­çš„è¯
                        result = session.run(
                            "MATCH (a)-[r:RELATION]->(b) WHERE a.name CONTAINS $keyword RETURN a.name as subject, type(r) as relation, b.name as target LIMIT 3",
                            keyword=keyword
                        )
                        records = result.data()
                        if records:
                            print(f"ğŸ•¸ï¸ KG: é€šè¿‡å…³é”®è¯ '{keyword}' æ‰¾åˆ°ç›¸å…³å…³ç³»")
                            break
            
            if records:
                # æ ¼å¼åŒ–è¿”å›ç»“æœ
                results = []
                for record in records:
                    results.append({
                        'subject': record['subject'],
                        'relation': record['relation'], 
                        'target': record['target']
                    })
                print(f"ğŸ•¸ï¸ KG: æŸ¥è¯¢ '{subject}' æ‰¾åˆ° {len(results)} æ¡å…³ç³»")
                return {'status': 'success', 'data': results}
            else:
                print(f"ğŸ•¸ï¸ KG: æœªæŸ¥è¯¢åˆ° '{subject}' ç›¸å…³çš„ä»»ä½•å…³ç³»ã€‚")
                return {'status': 'success', 'data': None}
class ProceduralMemory:
    def __init__(self, skills_dir='skills'):
        self.skills_dir = skills_dir;
        if not os.path.exists(self.skills_dir): os.makedirs(self.skills_dir)
        print(f"âœ… ç¨‹åºæ€§è®°å¿†æ¨¡å— (File System @ {skills_dir}) åˆå§‹åŒ–å®Œæˆã€‚")
    def store(self, skill_name: str, code: str):
        with open(os.path.join(self.skills_dir, f"{skill_name}.py"), "w", encoding="utf-8") as f: f.write(code)
        print(f"ğŸ› ï¸ ProcMem: å­˜å‚¨æ–°æŠ€èƒ½ '{skill_name}'ã€‚")
    def retrieve(self, skill_name: str, *args, **kwargs) -> Any:
        try:
            module_path = f"{self.skills_dir}.{skill_name}"; skill_module = __import__(module_path, fromlist=[None])
            result = skill_module.execute(*args, **kwargs); print(f"ğŸš€ ProcMem: æˆåŠŸæ‰§è¡ŒæŠ€èƒ½ '{skill_name}'ã€‚"); return result
        except (ImportError, AttributeError) as e: print(f"âŒ ProcMem: æ‰§è¡ŒæŠ€èƒ½ '{skill_name}' å¤±è´¥: {e}"); return None

# --- 3. å‘é‡è®°å¿† (Vector Memory) ---
class VectorMemory:
    def __init__(self, embedding_service_url: str, embedding_model_name: str, dimension: int, db_path='ltm.db'):
        self.embedding_service_url = embedding_service_url
        self.embedding_model_name = embedding_model_name
        self.dimension = dimension
        self._needs_save = False  # ğŸ†• ä¿å­˜æ ‡å¿—
        
        # åŠ è½½ç°æœ‰ç´¢å¼•æˆ–åˆ›å»ºæ–°ç´¢å¼•
        index_path = 'vector_index.faiss'
        mapping_path = 'vector_mapping.json'
        
        if os.path.exists(index_path):
            self.index = faiss.read_index(index_path)
            print(f"ğŸ“ åŠ è½½ç°æœ‰å‘é‡ç´¢å¼•: {self.index.ntotal} ä¸ªå‘é‡")
        else:
            self.index = faiss.IndexFlatL2(self.dimension)
            print(f"ğŸ†• åˆ›å»ºæ–°å‘é‡ç´¢å¼•")
        
        # åŠ è½½å‘é‡æ˜ å°„
        if os.path.exists(mapping_path):
            with open(mapping_path, 'r') as f:
                mapping_data = json.load(f)
                # å¤„ç†æ—§æ ¼å¼ï¼š{"0": "0", "1": "1", ...}
                self.vector_mapping = {int(k): v for k, v in mapping_data.items()}
            print(f"ğŸ“ åŠ è½½å‘é‡æ˜ å°„: {len(self.vector_mapping)} ä¸ªæ˜ å°„")
        else:
            self.vector_mapping = {}
            print(f"ğŸ†• åˆ›å»ºæ–°å‘é‡æ˜ å°„")
        
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS vector_metadata (
                vector_id INTEGER PRIMARY KEY,
                memory_type TEXT,
                text TEXT,
                metadata TEXT
            )
        """)
        self.conn.commit()
        print(f"âœ… å‘é‡è®°å¿†æ¨¡å— (Faiss + å¤–éƒ¨åµŒå…¥æœåŠ¡ @ {embedding_service_url}) åˆå§‹åŒ–å®Œæˆã€‚")
        print(f"   - ä½¿ç”¨æ¨¡å‹: {self.embedding_model_name}")
        print(f"   - å‘é‡ç»´åº¦: {self.dimension}")

    def _get_embedding(self, text: str) -> np.ndarray:
        try:
            payload = {"model": self.embedding_model_name, "input": [text]}
            response = requests.post(self.embedding_service_url, json=payload, timeout=10)
            response.raise_for_status()
            result = response.json()
            embedding = np.array(result['data'][0]['embedding'], dtype='float32')
            return embedding
        except requests.exceptions.RequestException as e:
            print(f"âŒ è°ƒç”¨åµŒå…¥æœåŠ¡å¤±è´¥: {e}"); raise
        except (KeyError, IndexError) as e:
            print(f"âŒ è§£æåµŒå…¥æœåŠ¡å“åº”å¤±è´¥: {e}"); raise

    def store(self, memory_type: str, text: str, metadata: Dict[str, Any]):
        embedding = self._get_embedding(text)
        
        # ç”Ÿæˆå”¯ä¸€çš„vector_idï¼Œä½¿ç”¨æ—¶é—´æˆ³+éšæœºæ•°ç¡®ä¿å”¯ä¸€æ€§
        import time
        import random
        vector_id = int(time.time() * 1000000) + random.randint(1000, 9999)
        
        # æ£€æŸ¥IDæ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™é‡æ–°ç”Ÿæˆ
        max_retries = 10
        for retry in range(max_retries):
            self.cursor.execute("SELECT COUNT(*) FROM vector_metadata WHERE vector_id = ?", (vector_id,))
            if self.cursor.fetchone()[0] == 0:
                break
            vector_id = int(time.time() * 1000000) + random.randint(1000, 9999)
            if retry == max_retries - 1:
                print(f"âŒ æ— æ³•ç”Ÿæˆå”¯ä¸€vector_idï¼Œé‡è¯•{max_retries}æ¬¡åå¤±è´¥")
                return
        
        # è®°å½•å½“å‰indexä½ç½®å’Œvector_idçš„æ˜ å°„
        current_index_pos = self.index.ntotal
        self.vector_mapping[current_index_pos] = vector_id
        
        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        self.index.add(np.array([embedding]))
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata['memory_type'] = memory_type
        metadata['text'] = text
        
        # å­˜å‚¨åˆ°æ•°æ®åº“ï¼Œæ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†æ•°æ®åº“é”å®š
        max_db_retries = 5
        for db_retry in range(max_db_retries):
            try:
                self.cursor.execute(
                    "INSERT INTO vector_metadata (vector_id, memory_type, content, metadata) VALUES (?, ?, ?, ?)",
                    (vector_id, memory_type, text, json.dumps(metadata, cls=EnhancedJSONEncoder))
                )
                self.conn.commit()
                break
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and db_retry < max_db_retries - 1:
                    import time as time_module
                    time_module.sleep(0.1 * (db_retry + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
                    continue
                else:
                    raise
            except sqlite3.IntegrityError as e:
                if "UNIQUE constraint failed" in str(e):
                    # IDå†²çªï¼Œé‡æ–°ç”Ÿæˆ
                    vector_id = int(time.time() * 1000000) + random.randint(1000, 9999)
                    self.vector_mapping[current_index_pos] = vector_id
                    if db_retry < max_db_retries - 1:
                        continue
                raise
        
        print(f"ğŸ’¾ VectorDB ({memory_type}): å­˜å‚¨å‘é‡ID {vector_id} - '{text[:30]}...'")
        
        # ğŸ†• æ ‡è®°éœ€è¦ä¿å­˜ï¼Œä½†ä¸ç«‹å³ä¿å­˜ï¼ˆé¿å…é¢‘ç¹I/Oï¼‰
        self._needs_save = True

    def _save_index_and_mapping(self):
        """ä¿å­˜å‘é‡ç´¢å¼•å’Œæ˜ å°„å…³ç³»åˆ°ç£ç›˜"""
        if not self._needs_save:
            return
            
        try:
            # ä¿å­˜å‘é‡ç´¢å¼•
            faiss.write_index(self.index, 'vector_index.faiss')
            
            # ä¿å­˜å‘é‡æ˜ å°„
            with open('vector_mapping.json', 'w', encoding='utf-8') as f:
                json.dump(self.vector_mapping, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“ å‘é‡ç´¢å¼•å’Œæ˜ å°„å·²ä¿å­˜ (ç´¢å¼•å¤§å°: {self.index.ntotal})")
            self._needs_save = False
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    def save_if_needed(self):
        """å¦‚æœæœ‰æ›´æ”¹åˆ™ä¿å­˜ç´¢å¼•å’Œæ˜ å°„"""
        self._save_index_and_mapping()

    def retrieve(self, query_text: str, k: int = 5, filter_by_type: Optional[str] = None) -> List[Dict[str, Any]]:
        query_embedding = self._get_embedding(query_text)
        distances, indices = self.index.search(np.array([query_embedding]), k * 2)
        results = []
        for i, idx in enumerate(indices[0]):
            if len(results) >= k:
                break
            # ä½¿ç”¨æ˜ å°„è·å–æ­£ç¡®çš„vector_id
            if idx in self.vector_mapping:
                vector_id = self.vector_mapping[idx]
                self.cursor.execute("SELECT metadata, memory_type FROM vector_metadata WHERE vector_id = ?", (vector_id,))
                row = self.cursor.fetchone()
                if row:
                    metadata = json.loads(row[0])
                    memory_type = row[1]
                    if filter_by_type and memory_type != filter_by_type:
                        continue
                    results.append({'metadata': metadata, 'score': float(distances[0][i])})
        print(f"ğŸ” VectorDB: æŸ¥è¯¢ '{query_text[:30]}...'ï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœã€‚")
        return results

# --- 7. è®°å¿†ç¼–æ’å™¨ (Memory Orchestrator) ---
class MemoryOrchestrator:
    def __init__(self):
        print("\n--- åˆå§‹åŒ–è®°å¿†ç¼–æ’å™¨ ---")
        self.redis_client = redis.Redis(decode_responses=True)
        try:
            self.redis_client.ping()
            print("ğŸ”— Redis è¿æ¥æˆåŠŸã€‚")
        except redis.exceptions.ConnectionError as e:
            print(f"âŒ Redis è¿æ¥å¤±è´¥: {e}\nè¯·ç¡®ä¿RedisæœåŠ¡å™¨æ­£åœ¨è¿è¡Œã€‚"); exit(1)
        db_path = 'ltm.db'
        self.vector_mem = VectorMemory(
            embedding_service_url="http://127.0.0.1:7999/v1/embeddings",
            embedding_model_name="qwen3-embedding-0.6b",
            dimension=1024,
            db_path=db_path
        )
        self.stm = ShortTermMemory(self.redis_client)
        self.wm = WorkingMemory(self.redis_client)
        self.structured_ltm = StructuredLTM(db_path=db_path)
        self.kg_mem = KnowledgeGraphMemory()
        self.procedural_mem = ProceduralMemory()
        print("--- è®°å¿†ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ ---\n")

    def store(self, memory_type: str, **kwargs):
        if memory_type == 'stm': 
            # æ”¯æŒæ–°ç‰ˆæ‘˜è¦å­˜å‚¨å’Œæ—§ç‰ˆæ¶ˆæ¯å­˜å‚¨
            if 'conversation_summary' in kwargs:
                # æ–°ç‰ˆæ‘˜è¦å­˜å‚¨
                self.stm.store_summary(
                    kwargs['conversation_id'], 
                    kwargs['conversation_summary'],
                    kwargs['round_id']
                )
            else:
                # æ—§ç‰ˆæ¶ˆæ¯å­˜å‚¨ï¼Œä¿æŒå‘åå…¼å®¹
                message = {
                    'role': kwargs.get('role', 'user'),
                    'content': kwargs.get('content', ''),
                    'timestamp': kwargs.get('timestamp', time.time())
                }
                self.stm.store(kwargs['conversation_id'], message)
        elif memory_type == 'wm': 
            # contexté‡å‘½åä¸ºdata
            data = kwargs.get('context', kwargs.get('data', {}))
            self.wm.store(kwargs['agent_id'], kwargs['task_id'], data)
        elif memory_type in ['episodic', 'semantic_fact', 'ltm_doc']:
            vec_type_map = {'semantic_fact': 'semantic', 'ltm_doc': 'ltm_doc', 'episodic': 'episodic'}
            self.vector_mem.store(vec_type_map[memory_type], kwargs['text'], kwargs['metadata'])
        elif memory_type == 'episodic': 
            # æƒ…èŠ‚è®°å¿†å­˜å‚¨
            vector_id = self.store_vector(kwargs['text'], kwargs.get('metadata', {}), 'episodic')
            return {'status': 'success', 'vector_id': vector_id}
        elif memory_type == 'semantic_fact': 
            # è¯­ä¹‰äº‹å®å­˜å‚¨
            vector_id = self.store_vector(kwargs['text'], kwargs.get('metadata', {}), 'semantic')
            return {'status': 'success', 'vector_id': vector_id}
        elif memory_type == 'ltm_preference': self.structured_ltm.store(kwargs['user_id'], kwargs['key'], kwargs['value'])
        elif memory_type == 'kg_relation': self.kg_mem.store(kwargs['subject'], kwargs['relation'], kwargs['obj'])
        elif memory_type == 'procedural_skill': self.procedural_mem.store(kwargs['skill_name'], kwargs['code'])
        else: raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„è®°å¿†ç±»å‹: {memory_type}")
    def retrieve(self, memory_type: str, **kwargs) -> Any:
        if memory_type == 'stm': 
            # æ”¯æŒæ—§ç‰ˆæ¶ˆæ¯æ£€ç´¢å’Œæ–°ç‰ˆæ‘˜è¦æ£€ç´¢
            if 'retrieve_type' in kwargs and kwargs['retrieve_type'] == 'summaries':
                return self.stm.retrieve_summaries(kwargs['conversation_id'], kwargs.get('last_k', 15))
            else:
                return self.stm.retrieve(kwargs['conversation_id'], kwargs.get('last_k', 10))
        elif memory_type == 'wm': 
            # æ”¯æŒåªä¼ task_idæˆ–åŒæ—¶ä¼ agent_idå’Œtask_id
            agent_id = kwargs.get('agent_id')
            task_id = kwargs.get('task_id')
            return self.wm.retrieve(agent_id, task_id)
        elif memory_type in ['episodic', 'semantic', 'semantic_fact', 'ltm_doc']:
            vec_type_map = {'semantic_fact': 'semantic', 'semantic': 'semantic', 'ltm_doc': 'ltm_doc', 'episodic': 'episodic'}
            return self.vector_mem.retrieve(kwargs['query_text'], kwargs.get('k', 5), vec_type_map.get(memory_type))
        elif memory_type == 'episodic': 
            # æƒ…èŠ‚è®°å¿†æ£€ç´¢
            results = self.retrieve_vector(kwargs['query_text'], memory_type='episodic')
            return {'status': 'success', 'data': results}
        elif memory_type == 'semantic_fact': 
            # è¯­ä¹‰äº‹å®æ£€ç´¢
            results = self.retrieve_vector(kwargs['query_text'], memory_type='semantic')
            return {'status': 'success', 'data': results}
        elif memory_type == 'ltm_preference': return self.structured_ltm.retrieve(kwargs['user_id'], kwargs['key'])
        elif memory_type == 'kg_relation': 
            # çŸ¥è¯†å›¾è°±æŸ¥è¯¢å·²ç»è¿”å›æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
            return self.kg_mem.retrieve(kwargs['subject'], kwargs['relation'])
        elif memory_type == 'procedural_skill': return self.procedural_mem.retrieve(kwargs['skill_name'], *kwargs.get('args', []), **kwargs.get('kwargs', {}))
        else: raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„è®°å¿†ç±»å‹: {memory_type}")
    def clear(self, memory_type: str, **kwargs):
        if memory_type == 'stm': self.stm.clear(kwargs['conversation_id'])
        elif memory_type == 'wm': self.wm.clear(kwargs['agent_id'], kwargs['task_id'])
        else: raise HTTPException(status_code=400, detail=f"æ¸…é™¤æ“ä½œä¸æ”¯æŒè®°å¿†ç±»å‹: {memory_type}")

# --- 8. FastAPI åº”ç”¨ [å·²ä¿®æ­£] ---

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ä½¿ç”¨ lifespan äº‹ä»¶å¤„ç†å™¨æ¥ç®¡ç†åº”ç”¨çš„å¯åŠ¨å’Œå…³é—­äº‹ä»¶ã€‚
    """
    # åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œçš„ä»£ç 
    print("ğŸš€ è®°å¿†æœåŠ¡å¯åŠ¨å®Œæˆï¼Œç­‰å¾…å®¢æˆ·ç«¯æ¤å…¥çŸ¥è¯†...")
    yield
    # åº”ç”¨å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç 
    print("ğŸ‘‹ è®°å¿†æœåŠ¡æ­£åœ¨å…³é—­ã€‚")

app = FastAPI(title="Agent Memory System API", version="1.4", lifespan=lifespan)
orchestrator = MemoryOrchestrator()

@app.get("/health")
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "message": "Memory service is running"}

class StoreRequest(BaseModel): memory_type: str; params: Dict[str, Any]
class RetrieveRequest(BaseModel): memory_type: str; params: Dict[str, Any]
class ClearRequest(BaseModel): memory_type: str; params: Dict[str, Any]
@app.post("/store")
def store_memory(request: StoreRequest):
    try: 
        orchestrator.store(request.memory_type, **request.params)
        # ğŸ†• å­˜å‚¨åä¿å­˜å‘é‡ç´¢å¼•ï¼ˆå¦‚æœæœ‰æ›´æ”¹ï¼‰
        orchestrator.vector_mem.save_if_needed()
        return {"status": "success"}
    except Exception as e: 
        print(f"âŒ APIå­˜å‚¨é”™è¯¯ - è®°å¿†ç±»å‹: {request.memory_type}, å‚æ•°: {request.params}, é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
@app.post("/retrieve")
def retrieve_memory(request: RetrieveRequest):
    try: 
        result = orchestrator.retrieve(request.memory_type, **request.params)
        # ğŸ”§ ä¿®å¤åŒå±‚åµŒå¥—ï¼šå¦‚æœresultå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if isinstance(result, dict) and 'status' in result:
            return result
        else:
            return {"status": "success", "data": result}
    except Exception as e: 
        print(f"âŒ APIé”™è¯¯ - è®°å¿†ç±»å‹: {request.memory_type}, å‚æ•°: {request.params}, é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
@app.post("/clear")
def clear_memory(request: ClearRequest):
    try: orchestrator.clear(request.memory_type, **request.params); return {"status": "success"}
    except Exception as e: raise HTTPException(status_code=500, detail=str(e))

# åŸæœ‰çš„ @app.on_event("startup") å·²è¢«ç§»é™¤

