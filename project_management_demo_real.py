# -*- coding: utf-8 -*-
import os
import requests
import json
import uuid
import time
import re
import logging
import importlib.util
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from conversation_value_filter import ConversationValueFilter, ConversationItem, FilterResult
from task_todo_manager import TaskTodoManager

# --- æ—¥å¿—é…ç½® ---
def setup_logging():
    """é…ç½®æ—¥å¿—è®°å½•ï¼Œè¾“å‡ºåˆ°å¤–éƒ¨æ–‡ä»¶"""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO) 
    fh = logging.FileHandler('project_management_demo.log', mode='w', encoding='utf-8', errors='replace')
    fh.setLevel(logging.INFO)
    debug_fh = logging.FileHandler('project_management_demo_debug.log', mode='w', encoding='utf-8', errors='replace')
    debug_fh.setLevel(logging.DEBUG)
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - [%(module)s:%(funcName)s:%(lineno)d] - %(message)s'
    )
    fh.setFormatter(formatter)
    debug_fh.setFormatter(formatter)
    logger.addHandler(fh)
    logger.addHandler(debug_fh)

logger = logging.getLogger(__name__)

# --- é…ç½® ---
load_dotenv()

# å…¨å±€å¸¸é‡
MEMORY_SERVICE_URL = "http://127.0.0.1:8000"
USER_ID = "project_manager_alice"
AGENT_ID = "agent_project_management_assistant"
SKILLS_DIR = 'skills'

# --- OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ– ---
try:
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    base_url = os.getenv("AZURE_OPENAI_ENDPOINT")
    model_name = os.getenv("AZURE_OPENAI_DEPLOYMENT")
    if not all([api_key, base_url, model_name]): raise ValueError("âŒ é”™è¯¯: Azure OpenAI é…ç½®ä¸å®Œæ•´ã€‚")
    azure_client = OpenAI(
        api_key=api_key,
        base_url=base_url,
        default_query={"api-version": "preview"}, 
        timeout=60.0
    )
    logger.info("Azure OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (ä½¿ç”¨ responses API)")
except Exception as e:
    logger.exception("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
    print(f"âŒ å…³é”®æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿— project_management_demo.logã€‚é”™è¯¯: {e}")
    exit(1)

# --- è¾…åŠ©å‡½æ•° ---
def call_memory_service(endpoint: str, payload: dict) -> dict:
    url = f"{MEMORY_SERVICE_URL}/{endpoint}"
    logger.debug(f"å‡†å¤‡è°ƒç”¨è®°å¿†æœåŠ¡: Endpoint={endpoint}, Payload={json.dumps(payload, ensure_ascii=False)}")
    try:
        response = requests.post(url, json=payload, timeout=15)
        response.raise_for_status()
        json_response = response.json()
        logger.debug(f"è®°å¿†æœåŠ¡å“åº”: {json.dumps(json_response, ensure_ascii=False)}")
        return json_response
    except requests.exceptions.RequestException as e:
        error_message = f"è°ƒç”¨è®°å¿†æœåŠ¡å¤±è´¥: {e}"
        logger.error(error_message)
        return {"status": "error", "detail": error_message}

class ProjectManagementAgent:
    def __init__(self, user_id, agent_id):
        self.user_id = user_id
        self.agent_id = agent_id
        self.conversation_history = []  # å½“å‰è½®æ¬¡çš„æ¨ç†å¯¹è¯
        self.conversation_id = str(uuid.uuid4())  # ä¸ºSTMåŒæ­¥ç”Ÿæˆä¼šè¯ID
        self.round_id = 0  # å¯¹è¯è½®æ¬¡è®¡æ•°å™¨
        
        logger.info(f"Agent {self.agent_id} æ­£åœ¨ä¸ºç”¨æˆ· {self.user_id} è¿›è¡Œåˆå§‹åŒ–...")
        logger.info(f"ä¼šè¯ID: {self.conversation_id}")
        
        # åˆå§‹åŒ–å¯¹è¯ä»·å€¼è¿‡æ»¤å™¨
        self.conversation_filter = ConversationValueFilter()
        logger.info("âœ… 3çº§æ¼æ–—è®°å¿†è¿‡æ»¤å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–Todoè¿½è¸ªç®¡ç†å™¨
        self.todo_manager = TaskTodoManager()
        logger.info("âœ… ä»»åŠ¡Todoè¿½è¸ªç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        self.tools_definitions, self.tool_functions = self._initialize_tools()
        logger.info("é¡¹ç›®ç®¡ç†Agentå·²å‡†å¤‡å°±ç»ªã€‚")

    def _initialize_tools(self):
        """[é¡¹ç›®ç®¡ç†ç‰ˆ] ä¸ºä¸ƒå¤§è®°å¿†æ¨¡å—æä¾›å®Œæ•´ã€ç²¾ç¡®çš„å·¥å…·é›†"""
        tool_functions = {}
        tools_definitions = []

        # 1. åŠ¨æ€åŠ è½½å¤–éƒ¨æŠ€èƒ½ (ç¨‹åºæ€§è®°å¿†)
        if not os.path.exists(SKILLS_DIR): os.makedirs(SKILLS_DIR); logger.info(f"æŠ€èƒ½ç›®å½• '{SKILLS_DIR}' ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»ºã€‚")
        for filename in os.listdir(SKILLS_DIR):
            if filename.endswith('.py') and not filename.startswith('__'):
                skill_name = filename[:-3]
                
                # è¿‡æ»¤ä¸ç¬¦åˆOpenAIå‡½æ•°åè§„èŒƒçš„æŠ€èƒ½åï¼ˆåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼‰
                if not re.match(r'^[a-zA-Z0-9_-]+$', skill_name):
                    logger.debug(f"è·³è¿‡ä¸ç¬¦åˆå‡½æ•°åè§„èŒƒçš„æŠ€èƒ½: {skill_name}")
                    continue
                
                try:
                    module_path = f"{SKILLS_DIR}.{skill_name}"
                    spec = importlib.util.spec_from_file_location(module_path, os.path.join(SKILLS_DIR, filename))
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)
                    if hasattr(module, 'get_skill_metadata'):
                        metadata = module.get_skill_metadata()
                        
                        # å…¼å®¹ä¸‰ç§å‚æ•°æ ¼å¼ï¼šåˆ—è¡¨ã€å­—å…¸æˆ–å®Œæ•´çš„OpenAI schema
                        params = metadata.get("parameters", [])
                        if isinstance(params, list):
                            # åˆ—è¡¨æ ¼å¼ï¼š['param1', 'param2']
                            params_schema = {
                                "type": "object",
                                "properties": {param: {"type": "string"} for param in params},
                                "required": params
                            }
                        elif isinstance(params, dict) and "type" in params:
                            # å®Œæ•´çš„OpenAI schemaæ ¼å¼
                            params_schema = params
                        else:
                            # å­—å…¸æ ¼å¼ï¼š{'param1': {'description': '...', 'required': True}}
                            params_schema = {
                                "type": "object", 
                                "properties": {k: {"type": "string", "description": v.get("description", "")} for k, v in params.items()}, 
                                "required": [k for k, v in params.items() if v.get("required")]
                            }
                        
                        tools_definitions.append({"type": "function", "name": skill_name, "description": metadata.get("description"), "parameters": params_schema})
                        tool_functions[skill_name] = (lambda s_name: lambda **kwargs: self._execute_skill(skill_name=s_name, kwargs=kwargs))(skill_name)
                        logger.info(f"æˆåŠŸåŠ¨æ€åŠ è½½[ç¨‹åºè®°å¿†]æŠ€èƒ½: {skill_name}")
                except Exception as e:
                    logger.error(f"åŠ è½½æŠ€èƒ½ {skill_name} å¤±è´¥: {e}")
        
        # 2. åŠ å…¥ä¸è®°å¿†æ¨¡å—ä¸€ä¸€å¯¹åº”çš„å†…ç½®å·¥å…·
        meta_tools_def = [
            {"type": "function", "name": "query_ltm_preference", "description": "æŸ¥è¯¢ç”¨æˆ·çš„ã€é•¿æœŸåå¥½è®°å¿†ã€‘ã€‚å½“ä½ éœ€è¦äº†è§£ç”¨æˆ·çš„ä¹ æƒ¯ã€å–œå¥½ï¼ˆå¦‚ç®¡ç†é£æ ¼ã€ä¼šè®®åå¥½ç­‰ï¼‰æ—¶å¿…é¡»ä½¿ç”¨æ­¤å·¥å…·ã€‚", "parameters": {"type": "object", "properties": {"key": {"type": "string", "description": "è¦æŸ¥è¯¢çš„åå¥½é”®åï¼Œä¾‹å¦‚ 'meeting_style' æˆ– 'management_style'ã€‚"}}, "required": ["key"]}},
            {"type": "function", "name": "query_episodic_memory", "description": "æŸ¥è¯¢ã€æƒ…èŠ‚è®°å¿†ã€‘ï¼Œå›é¡¾è¿‡å»å‘ç”Ÿçš„å…·ä½“äº‹ä»¶æˆ–å·²å®Œæˆçš„ä»»åŠ¡ã€‚ä¾‹å¦‚å›é¡¾ä¸Šæ¬¡çš„é¡¹ç›®é‡Œç¨‹ç¢‘ä¼šè®®æˆ–æŸ¥æ‰¾Sprintå›é¡¾ä¼šè®®è®°å½•ã€‚", "parameters": {"type": "object", "properties": {"query_text": {"type": "string", "description": "æè¿°ä½ è¦æŸ¥æ‰¾çš„äº‹ä»¶æˆ–ä»»åŠ¡çš„å…³é”®è¯ã€‚"}}, "required": ["query_text"]}},
            {"type": "function", "name": "query_semantic_memory", "description": "æŸ¥è¯¢ã€è¯­ä¹‰è®°å¿†ã€‘ï¼ŒæŸ¥æ‰¾å®¢è§‚äº‹å®ã€æ ‡å‡†æµç¨‹æˆ–é¡¹ç›®ç®¡ç†çŸ¥è¯†ã€‚ä¾‹å¦‚æŸ¥è¯¢æ•æ·å¼€å‘æœ€ä½³å®è·µæˆ–æŸ¥æ‰¾é£é™©ç®¡ç†æµç¨‹ã€‚", "parameters": {"type": "object", "properties": {"query_text": {"type": "string", "description": "æè¿°ä½ è¦æŸ¥æ‰¾çš„äº‹å®æˆ–çŸ¥è¯†çš„å…³é”®è¯ã€‚"}}, "required": ["query_text"]}},
            {"type": "function", "name": "query_knowledge_graph", "description": "æŸ¥è¯¢ã€çŸ¥è¯†å›¾è°±ã€‘ï¼Œæ¢ç´¢å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚ä¾‹å¦‚æŸ¥è¯¢Bobçš„æŠ€èƒ½å’ŒèŒè´£æˆ–æŸ¥è¯¢å›¢é˜Ÿåä½œå…³ç³»ã€‚", "parameters": {"type": "object", "properties": {"subject": {"type": "string", "description": "å…³ç³»çš„ä¸»ä½“"}, "relation": {"type": "string", "description": "è¦æŸ¥è¯¢çš„å…³ç³»ç±»å‹"}}, "required": ["subject", "relation"]}},
            {"type": "function", "name": "query_stm", "description": "æŸ¥è¯¢ã€çŸ­æœŸè®°å¿†STMã€‘ï¼Œè·å–å½“å‰å¯¹è¯ä¼šè¯ä¸­çš„å†å²æ¶ˆæ¯å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç”¨äºå›é¡¾æœ€è¿‘çš„å¯¹è¯å†…å®¹æˆ–æŸ¥æ‰¾ä¼šè¯ç›¸å…³çš„ä¸´æ—¶ä¿¡æ¯ã€‚", "parameters": {"type": "object", "properties": {"conversation_id": {"type": "string", "description": "å¯¹è¯ä¼šè¯IDï¼Œä¸å¡«åˆ™ä½¿ç”¨å½“å‰ä¼šè¯"}, "limit": {"type": "integer", "description": "è¿”å›çš„è®°å¿†æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤10"}}, "required": []}},
            {"type": "function", "name": "manage_working_memory", "description": "ç®¡ç†ã€å·¥ä½œè®°å¿†ã€‘ï¼Œç”¨äºè·Ÿè¸ªä¸€ä¸ªéœ€è¦å¤šæ­¥éª¤å®Œæˆçš„å¤æ‚ä»»åŠ¡ã€‚å¯ä»¥åˆ›å»º(create)ã€æ›´æ–°(update)ã€æ£€ç´¢(retrieve)æˆ–æ¸…é™¤(clear)ä¸€ä¸ªä»»åŠ¡ã€‚", "parameters": {"type": "object", "properties": {"action": {"type": "string", "description": "æ“ä½œç±»å‹ï¼Œå¯é€‰ 'create', 'update', 'retrieve', 'clear'"}, "task_id": {"type": "string", "description": "ä»»åŠ¡çš„å”¯ä¸€ID"}, "data": {"type": "object", "description": "åœ¨createæˆ–updateæ—¶ä¼ å…¥çš„ä»»åŠ¡æ•°æ®"}}, "required": ["action", "task_id"]}},
            {"type": "function", "name": "consolidate_memory", "description": "å½“ä½ æˆåŠŸä¸ºç”¨æˆ·å®Œæˆä¸€é¡¹é‡è¦ä»»åŠ¡åï¼Œè°ƒç”¨æ­¤å·¥å…·å°†å…³é”®æˆæœä½œä¸ºæ–°çš„ã€æƒ…èŠ‚è®°å¿†ã€‘å­˜å…¥é•¿æœŸè®°å¿†åº“ã€‚", "parameters": {"type": "object", "properties": {"summary": {"type": "string", "description": "å¯¹éœ€è¦è¢«è®°å¿†çš„æ ¸å¿ƒæˆæœçš„ç®€æ´æ¦‚æ‹¬ã€‚"}}, "required": ["summary"]}},
            # é¡¹ç›®ç®¡ç†ä¸“é¡¹æŠ€èƒ½
            {"type": "function", "name": "generate_gantt_chart", "description": "ç”Ÿæˆé¡¹ç›®ç”˜ç‰¹å›¾ï¼Œå±•ç¤ºä»»åŠ¡æ—¶é—´å®‰æ’å’Œä¾èµ–å…³ç³»ã€‚å¸®åŠ©é¡¹ç›®ç»ç†å¯è§†åŒ–é¡¹ç›®è¿›åº¦å’Œèµ„æºåˆ†é…ã€‚", "parameters": {"type": "object", "properties": {"project_name": {"type": "string", "description": "é¡¹ç›®åç§°"}, "tasks": {"type": "array", "description": "ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«nameã€durationã€dependencies", "items": {"type": "object", "properties": {"name": {"type": "string"}, "duration": {"type": "integer"}, "dependencies": {"type": "array", "items": {"type": "string"}}}}}, "start_date": {"type": "string", "description": "é¡¹ç›®å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD"}}, "required": []}},
            {"type": "function", "name": "assess_project_risks", "description": "è¯„ä¼°é¡¹ç›®é£é™©å¹¶ç”Ÿæˆé£é™©ç®¡ç†æŠ¥å‘Šã€‚åˆ†æé¡¹ç›®ä¸­çš„æ½œåœ¨é£é™©å¹¶æä¾›ç¼“è§£ç­–ç•¥ã€‚", "parameters": {"type": "object", "properties": {"project_type": {"type": "string", "description": "é¡¹ç›®ç±»å‹ï¼Œå¦‚e-commerce"}, "team_size": {"type": "integer", "description": "å›¢é˜Ÿè§„æ¨¡ï¼ˆäººæ•°ï¼‰"}, "budget": {"type": "integer", "description": "é¡¹ç›®é¢„ç®—ï¼ˆä¸‡å…ƒï¼‰"}, "duration_months": {"type": "integer", "description": "é¡¹ç›®å‘¨æœŸï¼ˆæœˆï¼‰"}}, "required": []}},
            {"type": "function", "name": "end_conversation", "description": "å½“ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºå¯¹è¯ç»“æŸæˆ–ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆæ—¶è°ƒç”¨ã€‚", "parameters": {"type": "object", "properties": {}}}
        ]
        tools_definitions.extend(meta_tools_def)
        tool_functions["query_ltm_preference"] = self._query_ltm_preference
        tool_functions["query_episodic_memory"] = self._query_episodic_memory
        tool_functions["query_semantic_memory"] = self._query_semantic_memory
        tool_functions["query_knowledge_graph"] = self._query_knowledge_graph
        tool_functions["query_stm"] = self._query_stm
        tool_functions["manage_working_memory"] = self._manage_working_memory
        tool_functions["consolidate_memory"] = self._consolidate_memory
        tool_functions["generate_gantt_chart"] = self._generate_gantt_chart
        tool_functions["assess_project_risks"] = self._assess_project_risks
        tool_functions["end_conversation"] = self._end_conversation
        
        logger.info(f"Agentå·¥å…·é›†åˆå§‹åŒ–å®Œæˆï¼Œå…±åŠ è½½ {len(tools_definitions)} ä¸ªå·¥å…·ã€‚")
        return tools_definitions, tool_functions

    def _get_system_prompt(self):
        """é¡¹ç›®ç®¡ç†åŠ©æ‰‹çš„ç³»ç»Ÿæç¤º"""
        return f"""ä½ æ˜¯{self.agent_id}ï¼Œä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®ç®¡ç†æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸ºé¡¹ç›®ç»ç†{self.user_id}æä¾›å…¨æ–¹ä½çš„é¡¹ç›®ç®¡ç†æ”¯æŒã€‚

**ã€ä½ çš„ä¸“ä¸šé¢†åŸŸã€‘**
- ğŸ“‹ é¡¹ç›®è§„åˆ’ä¸è¿›åº¦ç®¡ç†
- ğŸ‘¥ å›¢é˜Ÿåè°ƒä¸èµ„æºåˆ†é…  
- ğŸ“Š é£é™©è¯†åˆ«ä¸è´¨é‡æ§åˆ¶
- ğŸ’¡ æœ€ä½³å®è·µå»ºè®®ä¸å†³ç­–æ”¯æŒ
- ğŸ“ˆ æ•°æ®åˆ†æä¸æŠ¥å‘Šç”Ÿæˆ

**ã€å½“å‰é¡¹ç›®èƒŒæ™¯ã€‘**
ä½ æ­£åœ¨ååŠ©ç®¡ç†ä¸€ä¸ª"ç”µå•†å¹³å°é‡æ„é¡¹ç›®"ï¼š
- é¡¹ç›®é¢„ç®—ï¼š200ä¸‡
- é¡¹ç›®å‘¨æœŸï¼š6ä¸ªæœˆ
- å›¢é˜Ÿè§„æ¨¡ï¼š12äºº
- æ ¸å¿ƒåŠŸèƒ½ï¼šç”¨æˆ·ç³»ç»Ÿã€å•†å“ç®¡ç†ã€è®¢å•å¤„ç†ã€æ”¯ä»˜é›†æˆ
- æŠ€æœ¯æ ˆï¼šReact + Node.js + MongoDB + Redis + Docker

**ã€7å¤§è®°å¿†ç³»ç»Ÿä½¿ç”¨ç­–ç•¥ - å¤šè®°å¿†ååŒåŸåˆ™ã€‘**

âš ï¸ **é‡è¦**: å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œä½ å¿…é¡»æŸ¥è¯¢å¤šä¸ªè®°å¿†ç³»ç»Ÿæ¥è·å¾—å…¨é¢ä¿¡æ¯ï¼

**ã€è®°å¿†æŸ¥è¯¢ç»„åˆç­–ç•¥ã€‘**
- ğŸ“‹ **é¡¹ç›®è§„åˆ’ä»»åŠ¡**: query_episodic_memory(å†å²Sprint) + query_semantic_memory(æ•æ·æœ€ä½³å®è·µ) + query_knowledge_graph(å›¢é˜ŸæŠ€èƒ½)
- ğŸ‘¥ **å›¢é˜Ÿç®¡ç†é—®é¢˜**: query_ltm_preference(ç®¡ç†é£æ ¼) + query_knowledge_graph(å›¢é˜Ÿå…³ç³») + query_episodic_memory(å›¢é˜Ÿäº’åŠ¨å†å²)
- ğŸš¨ **é£é™©è¯„ä¼°**: query_episodic_memory(å†å²é—®é¢˜) + query_semantic_memory(é£é™©ç®¡ç†çŸ¥è¯†) + assess_project_riskså·¥å…·
- ğŸ“ˆ **é¡¹ç›®å›é¡¾**: query_episodic_memory(é¡¹ç›®å†å²) + query_stm(æœ€è¿‘è®¨è®º) + query_semantic_memory(å›é¡¾æµç¨‹)

**ã€å•ä¸€è®°å¿†ç³»ç»Ÿä½¿ç”¨åœºæ™¯ã€‘**
1. **çŸ­æœŸè®°å¿†STM (query_stm)** - å¯¹è¯è¿è´¯æ€§
   - ğŸ”‘ è§¦å‘è¯ï¼š"åˆšæ‰"ã€"ä¹‹å‰è¯´è¿‡"ã€"åˆšåˆšè®¨è®ºçš„"
   
2. **æƒ…èŠ‚è®°å¿† (query_episodic_memory)** - å†å²äº‹ä»¶æŸ¥è¯¢
   - ğŸ”‘ è§¦å‘è¯ï¼š"ä¸Šæ¬¡Sprint"ã€"é¡¹ç›®å†å²"ã€"ä¼šè®®è®°å½•"ã€"é‡Œç¨‹ç¢‘"
   
3. **è¯­ä¹‰è®°å¿† (query_semantic_memory)** - çŸ¥è¯†åº“æŸ¥è¯¢  
   - ğŸ”‘ è§¦å‘è¯ï¼š"æ ‡å‡†æµç¨‹"ã€"æœ€ä½³å®è·µ"ã€"æ•æ·å¼€å‘"ã€"é£é™©ç®¡ç†"
   
4. **é•¿æœŸåå¥½ (query_ltm_preference)** - ä¸ªäººä¹ æƒ¯
   - ğŸ”‘ è§¦å‘è¯ï¼š"æˆ‘çš„é£æ ¼"ã€"ä¹ æƒ¯åšæ³•"ã€"åå¥½"ã€"ç®¡ç†æ–¹å¼"
   
5. **çŸ¥è¯†å›¾è°± (query_knowledge_graph)** - å…³ç³»ç½‘ç»œ
   - ğŸ”‘ è§¦å‘è¯ï¼š"å›¢é˜Ÿæˆå‘˜"ã€"è°è´Ÿè´£"ã€"æŠ€èƒ½åˆ†å¸ƒ"ã€"åä½œå…³ç³»"
   
6. **å·¥ä½œè®°å¿† (manage_working_memory)** - å¤æ‚ä»»åŠ¡è·Ÿè¸ª
   - ğŸ”‘ åœºæ™¯ï¼šå¤šæ­¥éª¤é¡¹ç›®è§„åˆ’ã€é£é™©è¯„ä¼°ã€å›¢é˜Ÿé‡ç»„ç­‰
   
7. **ç¨‹åºè®°å¿† (skills)** - æ‰§è¡Œå…·ä½“æ“ä½œ
   - ğŸ”‘ è§¦å‘è¯ï¼š"ç”Ÿæˆç”˜ç‰¹å›¾"ã€"é£é™©è¯„ä¼°"ã€"æ•°æ®åˆ†æ"

**ã€æ™ºèƒ½å·¥ä½œæµç¨‹ã€‘**
1. ğŸ“¥ ç†è§£éœ€æ±‚ â†’ åˆ†æç”¨æˆ·æƒ³è¦ä»€ä¹ˆ
2. ğŸ§  æŸ¥è¯¢è®°å¿† â†’ è·å–ç›¸å…³å†å²å’ŒçŸ¥è¯†
3. ğŸ“Š åˆ†ææƒ…å†µ â†’ ç»“åˆé¡¹ç›®çŠ¶æ€å’Œå›¢é˜Ÿæƒ…å†µ
4. ğŸ’¡ åˆ¶å®šæ–¹æ¡ˆ â†’ æä¾›å…·ä½“å¯è¡Œçš„å»ºè®®
5. ğŸ› ï¸ æ‰§è¡Œä»»åŠ¡ â†’ è°ƒç”¨ç›¸åº”æŠ€èƒ½å®Œæˆæ“ä½œ  
6. ğŸ“š å½’æ¡£æˆæœ â†’ è®°å½•é‡è¦ç»“æœå’Œå†³ç­–

**ã€æ²Ÿé€šåŸåˆ™ã€‘**
- ä¸»åŠ¨æŸ¥è¯¢ç›¸å…³è®°å¿†ï¼Œæä¾›ä¸Šä¸‹æ–‡ä¸°å¯Œçš„å›ç­”
- ç»“åˆé¡¹ç›®å®é™…æƒ…å†µç»™å‡ºå¯æ“ä½œçš„å»ºè®®
- è¯†åˆ«é£é™©å’Œæœºä¼šï¼ŒåŠæ—¶æé†’
- ä¿æŒä¸“ä¸šä¸”æ˜“æ‡‚çš„æ²Ÿé€šé£æ ¼
- æ¯æ¬¡å®Œæˆé‡è¦ä»»åŠ¡åéƒ½è¦consolidate_memory

è®°ä½ï¼šä½ æ˜¯ä¸€ä¸ªçœŸæ­£ç†è§£é¡¹ç›®ç®¡ç†çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¦å……åˆ†åˆ©ç”¨7å±‚è®°å¿†ç³»ç»Ÿæä¾›ä¸“ä¸šã€ç²¾å‡†ã€æœ‰ä»·å€¼çš„æ”¯æŒï¼"""

    def run(self):
        """å¯åŠ¨Agentçš„ä¸»äº¤äº’å¾ªç¯"""
        print("\n" + "="*60)
        print("ğŸš€ é¡¹ç›®ç®¡ç†æ™ºèƒ½åŠ©æ‰‹")
        print(f"ä½ å¥½ {self.user_id}ï¼Œæˆ‘æ˜¯æ‚¨çš„é¡¹ç›®ç®¡ç†åŠ©æ‰‹ {self.agent_id}")
        print("ğŸ’¡ æˆ‘æ‹¥æœ‰å®Œæ•´çš„7å±‚è®°å¿†ç³»ç»Ÿï¼Œå¯ä»¥ååŠ©æ‚¨è¿›è¡Œï¼š")
        print("   ğŸ“‹ é¡¹ç›®è§„åˆ’ä¸ç”˜ç‰¹å›¾ç”Ÿæˆ")  
        print("   ğŸš¨ é£é™©è¯„ä¼°ä¸ç®¡ç†")
        print("   ğŸ‘¥ å›¢é˜Ÿåè°ƒä¸èµ„æºåˆ†é…")
        print("   ğŸ“Š é¡¹ç›®è¿›åº¦è·Ÿè¸ª")
        print("   ğŸ§  åŸºäºå†å²ç»éªŒçš„å†³ç­–æ”¯æŒ")
        print("\nè¾“å…¥ 'é€€å‡º' æ¥ç»“æŸå¯¹è¯")
        print("="*60)
        
        logger.info("é¡¹ç›®ç®¡ç†Agentäº¤äº’å¾ªç¯å¼€å§‹ã€‚")
        
        self.conversation_history = [{"role": "system", "content": self._get_system_prompt()}]
        
        while True:
            raw_input = input(f"\n{self.user_id} > "); user_input = raw_input.encode('utf-8', errors='replace').decode('utf-8'); logger.info(f"æ”¶åˆ°ç”¨æˆ·è¾“å…¥: '{user_input}'")
            if user_input.lower() in ['é€€å‡º', 'exit', 'quit']: 
                # å®Œæˆå½“å‰ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
                if self.todo_manager.current_task_id:
                    self.todo_manager.complete_task("ç”¨æˆ·ä¸»åŠ¨é€€å‡º")
                logger.info("ç”¨æˆ·è¯·æ±‚é€€å‡ºã€‚"); print("å†è§ï¼æœŸå¾…ä¸‹æ¬¡ä¸ºæ‚¨çš„é¡¹ç›®ç®¡ç†å·¥ä½œæä¾›æ”¯æŒï¼"); break
            
            # ğŸ¯ å¼€å§‹æ–°ä»»åŠ¡Todoè¿½è¸ª
            task_id = self.todo_manager.start_new_task(user_input)
            logger.info(f"ğŸ“‹ æ–°ä»»åŠ¡å¼€å§‹: {task_id}")
            
            # ğŸ§  åœ¨å¤„ç†ç”¨æˆ·è¾“å…¥å‰ï¼Œå…ˆè¿›è¡Œ3çº§æ¼æ–—è®°å¿†ä»·å€¼åˆ†æå’Œè½¬æ¢
            try:
                filter_result, consolidation_success = self._process_conversation_to_memory(user_input)
                logger.info(f"è®°å¿†è½¬æ¢å®Œæˆ - Level {filter_result.memory_level}, æˆåŠŸ: {consolidation_success}")
            except Exception as e:
                logger.error(f"è®°å¿†è½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")
            
            # ğŸ“ˆ æ–°è½®æ¬¡å¼€å§‹ï¼Œå¢åŠ è½®æ¬¡è®¡æ•°
            self.round_id += 1
            logger.info(f"ğŸ“ˆ å¼€å§‹ç¬¬ {self.round_id} è½®å¯¹è¯")
            
            # ğŸ§  æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡ï¼ˆSTMæ‘˜è¦ + å½“å‰å¯¹è¯ï¼‰
            enhanced_context = self._build_enhanced_context()
            
            # é‡æ–°æ„å»ºå¯¹è¯å†å²ï¼ŒåŒ…å«å†å²æ‘˜è¦å’Œå½“å‰ç”¨æˆ·è¾“å…¥
            self.conversation_history = enhanced_context
            self.conversation_history.append({"role": "user", "content": user_input})
            
            # ğŸ”„ å®æ—¶åŒæ­¥åˆ°STMï¼ˆæ—§ç‰ˆæ ¼å¼ï¼‰
            self._sync_message_to_stm({"role": "user", "content": user_input})
            
            final_answer = self._think_and_act_loop()
            print(f"\n{self.agent_id} > {final_answer}")
            
            assistant_message = {"role": "assistant", "content": final_answer}
            self.conversation_history.append(assistant_message)
            
            # ğŸ”„ å®æ—¶åŒæ­¥åˆ°STMï¼ˆæ—§ç‰ˆæ ¼å¼ï¼‰
            self._sync_message_to_stm(assistant_message)
            
            logger.info(f"Agentæœ€ç»ˆå›ç­”: '{final_answer}'")
            
            # ğŸ”š è½®æ¬¡ç»“æŸ - å­˜å‚¨å¯¹è¯æ‘˜è¦åˆ°STM
            self._finalize_conversation_round(user_input, final_answer)
            
            # ğŸ§  æ™ºèƒ½å®¹é‡ç®¡ç†
            self._manage_conversation_capacity()
            
            # ğŸ¯ å®Œæˆä»»åŠ¡Todoè¿½è¸ª
            self.todo_manager.complete_task(final_answer[:100] + "..." if len(final_answer) > 100 else final_answer)
            logger.info(f"ğŸ“‹ ä»»åŠ¡å®Œæˆ: {task_id}")
            
    def _think_and_act_loop(self, max_turns=15):
        """é‡‡ç”¨å¼ºåˆ¶å•å·¥å…·æ‰§è¡Œæ¨¡å¼ - å½»åº•è§£å†³Azure OpenAI call_idä¸åŒ¹é…é—®é¢˜"""
        logger.info("è¿›å…¥å¼ºåˆ¶å•å·¥å…·æ‰§è¡ŒTool Callingæ¨¡å¼...")
        
        for i in range(max_turns):
            logger.info(f"å¾ªç¯è½®æ¬¡ {i+1}/{max_turns}")
            try:
                request_args = {"model": model_name, "tools": self.tools_definitions, "input": self.conversation_history}
                logger.debug(f"å‘é€ç»™LLMçš„è¯·æ±‚å‚æ•°:\n{json.dumps(request_args, indent=2, ensure_ascii=False)}")
                response = azure_client.responses.create(**request_args)
            except Exception as e:
                logger.error("è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯")
                logger.exception(e)
                # å¿«é€Ÿæ¢å¤ç­–ç•¥ï¼šç›´æ¥é‡ç½®å¹¶ç»§ç»­
                if "400" in str(e) and "call_id" in str(e):
                    logger.warning("æ£€æµ‹åˆ°call_idä¸åŒ¹é…é”™è¯¯ï¼Œæ‰§è¡Œå¿«é€Ÿé‡ç½®")
                    system_msg = self.conversation_history[0]  # ç³»ç»Ÿæ¶ˆæ¯
                    user_msg = self.conversation_history[1]    # ç”¨æˆ·è¯·æ±‚
                    self.conversation_history = [system_msg, user_msg]
                    logger.info(f"å·²é‡ç½®å¯¹è¯å†å²ï¼Œä¿ç•™ {len(self.conversation_history)} æ¡åŸºç¡€æ¶ˆæ¯")
                    continue
                return "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ€è€ƒæ—¶é‡åˆ°äº†ä¸€ç‚¹é—®é¢˜ï¼Œè¯·æ‚¨ç¨åå†è¯•ã€‚"
            
            response_message = response.output[0]
            self.conversation_history.append(response_message.model_dump(exclude_none=True))
            
            tool_calls = [output for output in response.output if hasattr(output, 'type') and output.type == 'function_call']
            text_content = "".join([item.text for output in response.output if hasattr(output, 'type') and output.type == 'message' for item in output.content if hasattr(item, 'type') and item.type == 'output_text'])

            if tool_calls:
                logger.info(f"æ¨¡å‹å†³å®šè°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·ã€‚")
                if text_content: logger.info(f"æ¨¡å‹çš„ä¸­é—´æ€è€ƒè¿‡ç¨‹: {text_content}")
                
                # ğŸ”¥ å¼ºåˆ¶å•å·¥å…·æ‰§è¡Œç­–ç•¥ï¼šå½»åº•é¿å…å¤šå·¥å…·çŠ¶æ€å†²çª
                executed_tools = []
                
                # åªæ‰§è¡Œç¬¬ä¸€ä¸ªå·¥å…·ï¼Œå…¶ä»–å·¥å…·åœ¨ä¸‹ä¸€è½®å¤„ç†
                tool_call = tool_calls[0]
                if len(tool_calls) > 1:
                    logger.warning(f"æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨ï¼Œå¼ºåˆ¶æ‰§è¡Œå•å·¥å…·æ¨¡å¼ï¼Œä»…æ‰§è¡Œ: {tool_call.name}")
                
                function_name = tool_call.name
                function_to_call = self.tool_functions.get(function_name)
                
                # ç¡®ä¿call_idå­˜åœ¨
                if not hasattr(tool_call, 'call_id') or not tool_call.call_id:
                    logger.error(f"å·¥å…·è°ƒç”¨ {function_name} ç¼ºå°‘call_idï¼Œè·³è¿‡æ‰§è¡Œ")
                    continue
                
                if not function_to_call:
                    observation_content = f"é”™è¯¯: æœªçŸ¥çš„å·¥å…· '{function_name}'"
                    logger.error(observation_content)
                else:
                    try:
                        function_args = json.loads(tool_call.arguments)
                        logger.info(f"å‡†å¤‡æ‰§è¡Œå·¥å…· '{function_name}'ï¼Œå‚æ•°: {function_args}")
                        
                        # ğŸ¯ Todoæ£€æŸ¥ï¼šé¿å…é‡å¤æ‰§è¡Œç›¸åŒæ“ä½œ
                        should_skip, cached_result = self.todo_manager.should_skip_action(function_name, function_args)
                        
                        if should_skip:
                            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°é‡å¤æ“ä½œï¼Œä½¿ç”¨ç¼“å­˜ç»“æœ: {function_name}")
                            observation = cached_result
                            observation_content = json.dumps(observation, ensure_ascii=False)
                        else:
                            # æ‰§è¡Œæ–°æ“ä½œ
                            start_time = time.time()
                            observation = function_to_call(**function_args)
                            execution_time = time.time() - start_time
                            
                            # è®°å½•æ“ä½œå®Œæˆ
                            self.todo_manager.mark_action_completed(function_name, function_args, observation, execution_time)
                            observation_content = json.dumps(observation, ensure_ascii=False)
                        
                        logger.info(f"å·¥å…· '{function_name}' çš„è§‚å¯Ÿç»“æœ: {observation}")
                    except Exception as e:
                        logger.exception(f"æ‰§è¡Œå·¥å…· '{function_name}' æ—¶å‡ºé”™")
                        observation_content = json.dumps({"status": "error", "detail": str(e)})
                
                # ç«‹å³æ·»åŠ å·¥å…·è¾“å‡º
                self.conversation_history.append({
                    "type": "function_call_output", 
                    "call_id": tool_call.call_id, 
                    "output": observation_content
                })
                
                logger.debug(f"å·²æ·»åŠ å·¥å…·è¾“å‡ºï¼Œcall_id: {tool_call.call_id}")
                executed_tools.append(function_name)
                
                logger.info(f"æœ¬è½®æ‰§è¡Œäº† {len(executed_tools)} ä¸ªå·¥å…·: {executed_tools}")
                continue
            else:
                logger.info("æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œåˆ¤å®šä¸ºæœ€ç»ˆç­”æ¡ˆã€‚"); return text_content
        logger.warning(f"å·²è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° {max_turns}ï¼Œå¼ºåˆ¶é€€å‡ºå¾ªç¯ã€‚"); return "æŠ±æ­‰ï¼Œç»è¿‡å‡ è½®æ·±åº¦æ€è€ƒåï¼Œæˆ‘ä»ç„¶æ— æ³•æ‰¾åˆ°è§£å†³æ‚¨è¯·æ±‚çš„æœ‰æ•ˆæ–¹æ³•ã€‚"

    def _execute_skill(self, skill_name: str, args: list = [], kwargs: dict = {}) -> dict:
        logger.info(f"åº•å±‚æŠ€èƒ½æ‰§è¡Œå™¨: skill_name={skill_name}, args={args}, kwargs={kwargs}")
        params = {'skill_name': skill_name, 'args': args, 'kwargs': kwargs}; payload = {"memory_type": "procedural_skill", "params": params}
        return call_memory_service('retrieve', payload)

    # --- æ–°å¢çš„ã€ä¸è®°å¿†æ¨¡å—ä¸€ä¸€å¯¹åº”çš„å·¥å…·å®ç° ---
    def _query_ltm_preference(self, key: str) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [query_ltm_preference]: key='{key}'")
        
        # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ keyæ˜ å°„é€»è¾‘ï¼ŒåŒ¹é…å®é™…æ•°æ®åº“ä¸­çš„keyæ ¼å¼
        key_mapping = {
            "ç®¡ç†é£æ ¼": "work_decision_making_style",
            "å†³ç­–é£æ ¼": "work_decision_making_style", 
            "æ•°æ®é©±åŠ¨": "work_decision_making_style",
            "æ²Ÿé€šé£æ ¼": "communication_style",
            "ä¼šè®®é£æ ¼": "meeting_time_preference",
            "ä¼šè®®æ—¶é—´": "meeting_time_preference",
            "ä¼šè®®åå¥½": "meeting_meeting_time_preference"
        }
        
        # å°è¯•æ˜ å°„keyï¼Œå¦‚æœæ²¡æœ‰æ˜ å°„å°±ä½¿ç”¨åŸkey
        mapped_key = key_mapping.get(key, key)
        logger.info(f"ğŸ”„ Keyæ˜ å°„: '{key}' -> '{mapped_key}'")
        
        payload = {"memory_type": "ltm_preference", "params": {"user_id": self.user_id, "key": mapped_key}}
        return call_memory_service('retrieve', payload)

    def _query_episodic_memory(self, query_text: str) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [query_episodic_memory]: query_text='{query_text}'")
        payload = {"memory_type": "episodic", "params": {"query_text": query_text}}
        return call_memory_service('retrieve', payload)

    def _query_semantic_memory(self, query_text: str) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [query_semantic_memory]: query_text='{query_text}'")
        payload = {"memory_type": "semantic_fact", "params": {"query_text": query_text}}
        return call_memory_service('retrieve', payload)

    def _query_knowledge_graph(self, subject: str, relation: str) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [query_knowledge_graph]: subject='{subject}', relation='{relation}'")
        payload = {"memory_type": "kg_relation", "params": {"subject": subject, "relation": relation}}
        return call_memory_service('retrieve', payload)
    
    def _query_stm(self, conversation_id: str = None, limit: int = 10) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [query_stm]: conversation_id='{conversation_id or self.conversation_id}', limit={limit}")
        payload = {"memory_type": "stm", "params": {
            "conversation_id": conversation_id or self.conversation_id,
            "limit": limit
        }}
        return call_memory_service('retrieve', payload)   
    
    def _manage_working_memory(self, action: str, task_id: str, data: dict = None) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [manage_working_memory]: action='{action}', task_id='{task_id}'")
        if action in ['create', 'update']:
            payload = {"memory_type": "wm", "params": {"agent_id": self.agent_id, "task_id": task_id, "data": data}}
            return call_memory_service('store', payload)
        elif action == 'retrieve':
            payload = {"memory_type": "wm", "params": {"task_id": task_id}}
            return call_memory_service('retrieve', payload)
        elif action == 'clear':
            payload = {"memory_type": "wm", "params": {"agent_id": self.agent_id, "task_id": task_id}}
            return call_memory_service('clear', payload)
        return {"status": "error", "detail": "æ— æ•ˆçš„action"}

    def _consolidate_memory(self, summary: str) -> dict:
        logger.info(f"æ‰§è¡Œå·¥å…· [consolidate_memory]: æ ¸å¿ƒå†…å®¹='{summary}'")
        payload = {"memory_type": "episodic", "params": {"text": f"ä»»åŠ¡æ€»ç»“: {summary}", "metadata": {"user_id": self.user_id, "type": "task_summary", "timestamp": time.time()}}}
        result = call_memory_service('store', payload)
        if result.get("status") == "success": return {"status": "success", "detail": "å…³é”®æˆæœå·²æˆåŠŸå½’æ¡£ã€‚"}
        else: return {"status": "error", "detail": f"å½’æ¡£è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯: {result.get('detail')}"}

    # === é¡¹ç›®ç®¡ç†ä¸“é¡¹æŠ€èƒ½å®ç° ===
    def _generate_gantt_chart(self, project_name=None, tasks=None, start_date=None):
        """ç”Ÿæˆé¡¹ç›®ç”˜ç‰¹å›¾"""
        try:
            # å¯¼å…¥ç”˜ç‰¹å›¾ç”ŸæˆæŠ€èƒ½
            import sys
            import os
            skills_path = os.path.join(os.path.dirname(__file__), 'skills')
            if skills_path not in sys.path:
                sys.path.append(skills_path)
            
            from project_gantt_generator import execute
            
            # è®¾ç½®é»˜è®¤å€¼
            if project_name is None:
                project_name = "ç”µå•†å¹³å°é‡æ„é¡¹ç›®"
            
            result = execute(project_name=project_name, tasks=tasks, start_date=start_date)
            
            if result["success"]:
                return f"âœ… ç”˜ç‰¹å›¾ç”ŸæˆæˆåŠŸï¼\n\n{result['text_display']}\n\nğŸ’¡ ç”˜ç‰¹å›¾æ•°æ®å·²ç”Ÿæˆï¼Œæ€»å·¥æœŸï¼š{result['data']['project']['total_duration']}å¤©"
            else:
                return f"âŒ ç”˜ç‰¹å›¾ç”Ÿæˆå¤±è´¥ï¼š{result['message']}"
                
        except Exception as e:
            logger.error(f"ç”˜ç‰¹å›¾ç”Ÿæˆå‡ºé”™ï¼š{e}")
            return f"âŒ ç”˜ç‰¹å›¾ç”Ÿæˆå‡ºé”™ï¼š{str(e)}"

    def _assess_project_risks(self, project_type=None, team_size=None, budget=None, duration_months=None):
        """è¯„ä¼°é¡¹ç›®é£é™©"""
        try:
            # å¯¼å…¥é£é™©è¯„ä¼°æŠ€èƒ½
            import sys
            import os
            skills_path = os.path.join(os.path.dirname(__file__), 'skills')
            if skills_path not in sys.path:
                sys.path.append(skills_path)
            
            from project_risk_assessor import execute
            
            # è®¾ç½®é»˜è®¤å€¼ï¼ˆç”µå•†é‡æ„é¡¹ç›®çš„å‚æ•°ï¼‰
            if project_type is None:
                project_type = "e-commerce"
            if team_size is None:
                team_size = 12
            if budget is None:
                budget = 200
            if duration_months is None:
                duration_months = 6
            
            result = execute(project_type=project_type, team_size=team_size, budget=budget, duration_months=duration_months)
            
            if result["success"]:
                summary = result["summary"]
                return f"âœ… é£é™©è¯„ä¼°å®Œæˆï¼\n\nğŸ“Š è¯„ä¼°æ‘˜è¦ï¼š\nâ€¢ æ€»é£é™©æ•°ï¼š{summary['total_risks']}\nâ€¢ é«˜é£é™©é¡¹ï¼š{summary['high_risks']}\nâ€¢ æœ€å¤§é£é™©ï¼š{summary['top_risk']}\n\n{result['report_text']}"
            else:
                return f"âŒ é£é™©è¯„ä¼°å¤±è´¥ï¼š{result['message']}"
                
        except Exception as e:
            logger.error(f"é£é™©è¯„ä¼°å‡ºé”™ï¼š{e}")
            return f"âŒ é£é™©è¯„ä¼°å‡ºé”™ï¼š{str(e)}"
    
    def _process_conversation_to_memory(self, user_input: str, conversation_id: str = None):
        """ğŸ§  3çº§æ¼æ–—è®°å¿†è½¬åŒ– - æ™ºèƒ½åˆ†æå¯¹è¯ä»·å€¼å¹¶è½¬æ¢ä¸ºç›¸åº”è®°å¿†ç±»å‹"""
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
        
        logger.info(f"ğŸ“Š å¼€å§‹3çº§æ¼æ–—è®°å¿†ä»·å€¼åˆ†æ...")
        
        # åˆ›å»ºå¯¹è¯é¡¹ç›®
        conversation_item = ConversationItem(
            content=user_input,
            timestamp=time.time(),
            role='user',
            user_id=self.user_id
        )
        
        # è¿›è¡Œ3çº§æ¼æ–—è¿‡æ»¤åˆ†æ
        filter_result = self.conversation_filter.filter_conversation(conversation_item)
        
        logger.info(f"ğŸ“ˆ 3çº§æ¼æ–—åˆ†æç»“æœ:")
        logger.info(f"  è¿‡æ»¤é˜¶æ®µ: {filter_result.filter_stage}")
        logger.info(f"  è®°å¿†ç­‰çº§: Level {filter_result.memory_level}")
        logger.info(f"  ç½®ä¿¡åº¦: {filter_result.confidence:.3f}")
        logger.info(f"  å¤„ç†æ—¶é—´: {filter_result.processing_time:.3f}ç§’")
        logger.info(f"  åˆ¤æ–­ç†ç”±: {filter_result.reasoning}")
        
        consolidation_success = False
        
        # æ ¹æ®è®°å¿†ç­‰çº§è¿›è¡Œä¸åŒçš„å­˜å‚¨ç­–ç•¥
        if filter_result.memory_level == 1:
            logger.info("ğŸ—‘ï¸  Level 1åˆ¤æ–­: å¯¹è¯ä»·å€¼è¾ƒä½ï¼Œä¸åšæŒä¹…åŒ–å­˜å‚¨")
            consolidation_success = True
            
        elif filter_result.memory_level == 2:
            # Level 2: å­˜å‚¨ä¸ºæƒ…èŠ‚è®°å¿†
            episodic_text = f"ç”¨æˆ·å¯¹è¯è®°å½•: {user_input}"
            payload = {"memory_type": "episodic", "params": {
                'text': episodic_text,
                'metadata': {
                    'user_id': self.user_id,
                    'conversation_id': conversation_id,
                    'timestamp': time.time(),
                    'filter_confidence': filter_result.confidence,
                    'filter_stage': filter_result.filter_stage
                }
            }}
            result = call_memory_service('store', payload)
            consolidation_success = result.get('status') == 'success'
            if consolidation_success:
                logger.info("ğŸ“ Level 2è½¬åŒ–: æˆåŠŸå­˜å‚¨ä¸ºæƒ…èŠ‚è®°å¿†")
            
        elif filter_result.memory_level == 3:
            # Level 3: æå–ç”¨æˆ·åå¥½
            if any(keyword in user_input for keyword in ["å–œæ¬¢", "åå¥½", "ä¹ æƒ¯", "å€¾å‘", "çˆ±å¥½"]):
                preference_key = f"extracted_preference_{int(time.time())}"
                preference_value = f"ä»å¯¹è¯æå–: {user_input}"
                payload = {"memory_type": "ltm_preference", "params": {
                    'user_id': self.user_id,
                    'key': preference_key,
                    'value': preference_value
                }}
                result = call_memory_service('store', payload)
                consolidation_success = result.get('status') == 'success'
                if consolidation_success:
                    logger.info("âš™ï¸  Level 3è½¬åŒ–: æˆåŠŸæå–å¹¶å­˜å‚¨ç”¨æˆ·åå¥½")
            
        elif filter_result.memory_level == 4:
            # Level 4: æå–ç¨‹åºæ€§çŸ¥è¯†
            if any(keyword in user_input for keyword in ["æµç¨‹", "æ­¥éª¤", "å¦‚ä½•", "æ–¹æ³•", "æ“ä½œ"]):
                skill_name = f"extracted_procedure_{int(time.time())}"
                skill_code = f"""
# ä»å¯¹è¯ä¸­æå–çš„ç¨‹åºæ€§çŸ¥è¯†
def execute():
    '''
    ç”¨æˆ·è¯¢é—®: {user_input}
    æå–æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
    '''
    return "ç¨‹åºæ€§çŸ¥è¯†æ‰§è¡Œå®Œæˆ"
"""
                payload = {"memory_type": "procedural_skill", "params": {
                    'skill_name': skill_name,
                    'code': skill_code
                }}
                result = call_memory_service('store', payload)
                consolidation_success = result.get('status') == 'success'
                if consolidation_success:
                    logger.info("ğŸ”§ Level 4è½¬åŒ–: æˆåŠŸæå–å¹¶å­˜å‚¨ç¨‹åºæ€§çŸ¥è¯†")
            
        elif filter_result.memory_level == 5:
            # Level 5: å­˜å‚¨ä¸ºè¯­ä¹‰çŸ¥è¯†
            semantic_text = f"é‡è¦æ¦‚å¿µè®¨è®º: {user_input}"
            payload = {"memory_type": "semantic_fact", "params": {
                'text': semantic_text,
                'metadata': {
                    'source': 'conversation_extraction',
                    'importance': 'high',
                    'user_id': self.user_id,
                    'timestamp': time.time(),
                    'filter_confidence': filter_result.confidence
                }
            }}
            result = call_memory_service('store', payload)
            consolidation_success = result.get('status') == 'success'
            if consolidation_success:
                logger.info("ğŸ§  Level 5è½¬åŒ–: æˆåŠŸå­˜å‚¨ä¸ºè¯­ä¹‰çŸ¥è¯†")
        
        return filter_result, consolidation_success
    
    def _sync_message_to_stm(self, message):
        """ğŸ”„ å®æ—¶åŒæ­¥æ¶ˆæ¯åˆ°çŸ­æœŸè®°å¿†"""
        try:
            content = f"[{message['role']}] {message['content']}"
            # ä¿®å¤å‚æ•°ç»“æ„ï¼šroleå’Œtimestampéœ€è¦ä½œä¸ºé¡¶çº§å‚æ•°
            payload = {"memory_type": "stm", "params": {
                "conversation_id": self.conversation_id,
                "content": content,
                "role": message["role"],
                "timestamp": datetime.now().isoformat(),
                "user_id": self.user_id
            }}
            result = call_memory_service('store', payload)
            if result.get("status") == "success":
                logger.debug(f"ğŸ”„ æ¶ˆæ¯å·²åŒæ­¥åˆ°STM: {content[:50]}...")
            else:
                logger.warning(f"âš ï¸ STMåŒæ­¥å¤±è´¥: {result}")
        except Exception as e:
            logger.warning(f"âš ï¸ STMåŒæ­¥å¤±è´¥: {e}")

    def _manage_conversation_capacity(self):
        """ğŸ§  æ™ºèƒ½å®¹é‡ç®¡ç† - å·¥ä½œè®°å¿†ä¸STMåè°ƒ"""
        max_working_memory = 20  # å·¥ä½œè®°å¿†æœ€å¤§å®¹é‡
        
        if len(self.conversation_history) > max_working_memory:
            # è½¬ç§»è¾ƒæ—©çš„å¯¹è¯åˆ°STMå¹¶ä»å·¥ä½œè®°å¿†ç§»é™¤
            overflow_count = len(self.conversation_history) - max_working_memory
            transferred_messages = []
            
            for i in range(overflow_count):
                old_message = self.conversation_history.pop(1)  # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼Œä»ç´¢å¼•1å¼€å§‹ç§»é™¤
                # ç¡®ä¿å·²åŒæ­¥åˆ°STM
                self._sync_message_to_stm(old_message)
                transferred_messages.append(old_message)
            
            logger.info(f"ğŸ§  å·¥ä½œè®°å¿†å®¹é‡ç®¡ç†: è½¬ç§» {overflow_count} æ¡æ¶ˆæ¯åˆ°STM")
            
        # å®šæœŸè§¦å‘STMâ†’é•¿æœŸè®°å¿†è½¬åŒ–
        if len(self.conversation_history) % 10 == 0:
            self._trigger_memory_consolidation()

    def _trigger_memory_consolidation(self):
        """ğŸ”„ è§¦å‘è®°å¿†æ•´åˆ - STMå‘é•¿æœŸè®°å¿†è½¬åŒ–"""
        try:
            # è·å–å½“å‰å¯¹è¯çš„STMå†…å®¹
            payload = {"memory_type": "stm", "params": {
                "conversation_id": self.conversation_id,
                "limit": 50
            }}
            stm_result = call_memory_service('retrieve', payload)
            
            if stm_result.get("status") == "success":
                stm_memories = stm_result.get("data", [])
                
                if stm_memories and len(stm_memories) > 10:
                    # æ‰¹é‡åˆ†æå¹¶è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†
                    consolidated_content = "\n".join([
                        mem.get('content', '') for mem in stm_memories if mem.get('content')
                    ])
                    
                    # é€šè¿‡è®°å¿†æ¼æ–—ç³»ç»Ÿè‡ªåŠ¨åˆ†ç±»å’Œå­˜å‚¨
                    payload = {"memory_type": "episodic", "params": {
                        "text": f"å¯¹è¯æ•´åˆè®°å¿† [{self.conversation_id}]: {consolidated_content}",
                        "metadata": {
                            "conversation_id": self.conversation_id,
                            "consolidation_timestamp": datetime.now().isoformat(),
                            "source": "stm_consolidation",
                            "user_id": self.user_id
                        }
                    }}
                    
                    result = call_memory_service('store', payload)
                    if result.get("status") == "success":
                        logger.info(f"ğŸ”„ è®°å¿†æ•´åˆå®Œæˆ: STMâ†’é•¿æœŸè®°å¿† ({len(stm_memories)} æ¡)")
                    else:
                        logger.warning(f"âš ï¸ é•¿æœŸè®°å¿†å­˜å‚¨å¤±è´¥: {result}")
                        
        except Exception as e:
            logger.warning(f"âš ï¸ è®°å¿†æ•´åˆå¤±è´¥: {e}")

    def _build_enhanced_context(self):
        """ğŸ§  æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡ï¼šSTMå†å²æ‘˜è¦ + ç³»ç»Ÿæç¤º"""
        enhanced_context = [{"role": "system", "content": self._get_system_prompt()}]
        
        try:
            # è·å–STMä¸­çš„å†å²å¯¹è¯æ‘˜è¦
            payload = {
                "memory_type": "stm", 
                "params": {
                    "conversation_id": self.conversation_id,
                    "retrieve_type": "summaries",
                    "last_k": 15  # è·å–æœ€è¿‘15è½®çš„æ‘˜è¦
                }
            }
            stm_result = call_memory_service('retrieve', payload)
            
            if stm_result.get("status") == "success":
                stm_summaries = stm_result.get("data", [])
                
                if stm_summaries:
                    # æ„å»ºå†å²ä¸Šä¸‹æ–‡æ‘˜è¦
                    history_summary = "## ğŸ“š å†å²å¯¹è¯æ‘˜è¦\n"
                    for summary in stm_summaries:
                        round_info = f"**è½®æ¬¡ {summary.get('round_id', 'N/A')}**: "
                        user_req = summary.get('user_request', '')[:100] + "..."
                        final_ans = summary.get('final_answer', '')[:150] + "..."
                        memories_used = summary.get('memories_used', [])
                        
                        history_summary += f"{round_info}\n"
                        history_summary += f"ç”¨æˆ·è¯·æ±‚: {user_req}\n"
                        history_summary += f"æœ€ç»ˆå›ç­”: {final_ans}\n"
                        if memories_used:
                            history_summary += f"ä½¿ç”¨è®°å¿†: {', '.join(memories_used[:3])}\n"
                        history_summary += "\n---\n"
                    
                    # æ·»åŠ å†å²æ‘˜è¦åˆ°ä¸Šä¸‹æ–‡
                    enhanced_context.append({
                        "role": "system", 
                        "content": history_summary + "\n## ğŸ¯ å½“å‰å¯¹è¯\nä»¥ä¸‹æ˜¯å½“å‰è½®æ¬¡çš„å¯¹è¯ï¼š"
                    })
                    
                    logger.info(f"ğŸ“š å·²åŠ è½½ {len(stm_summaries)} è½®å†å²å¯¹è¯æ‘˜è¦åˆ°ä¸Šä¸‹æ–‡")
                else:
                    logger.info("ğŸ“š æš‚æ— å†å²å¯¹è¯æ‘˜è¦")
            else:
                logger.warning(f"âš ï¸ è·å–STMæ‘˜è¦å¤±è´¥: {stm_result}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        
        return enhanced_context

    def _finalize_conversation_round(self, user_input: str, final_answer: str):
        """ğŸ”š å¯¹è¯è½®æ¬¡ç»“æŸå¤„ç†ï¼šæå–è®°å¿†å¹¶å­˜å‚¨æ‘˜è¦"""
        try:
            # æå–æœ¬è½®ä½¿ç”¨çš„è®°å¿†ç±»å‹ï¼ˆä»å·¥å…·è°ƒç”¨ä¸­è·å–ï¼‰
            memories_used = self._extract_memories_used_in_round()
            
            # æ„å»ºå¯¹è¯æ‘˜è¦
            conversation_summary = {
                "round_id": self.round_id,
                "timestamp": datetime.now().isoformat(),
                "user_request": user_input,
                "final_answer": final_answer,
                "memories_used": memories_used,
                "conversation_length": len(self.conversation_history)
            }
            
            # å­˜å‚¨åˆ°STMæ‘˜è¦ç³»ç»Ÿ
            payload = {
                "memory_type": "stm",
                "params": {
                    "conversation_id": self.conversation_id,
                    "conversation_summary": conversation_summary,
                    "round_id": self.round_id
                }
            }
            
            result = call_memory_service('store', payload)
            if result.get("status") == "success":
                logger.info(f"ğŸ”š è½®æ¬¡ {self.round_id} æ‘˜è¦å·²å­˜å‚¨åˆ°STM")
            else:
                logger.warning(f"âš ï¸ è½®æ¬¡æ‘˜è¦å­˜å‚¨å¤±è´¥: {result}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ è½®æ¬¡ç»“æŸå¤„ç†å¤±è´¥: {e}")

    def _extract_memories_used_in_round(self):
        """ğŸ“Š ä»å½“å‰è½®æ¬¡çš„å¯¹è¯ä¸­æå–ä½¿ç”¨çš„è®°å¿†ç±»å‹"""
        memories_used = []
        
        # åˆ†æå¯¹è¯å†å²ä¸­çš„åŠ©æ‰‹æ¶ˆæ¯ï¼ŒæŸ¥æ‰¾å·¥å…·è°ƒç”¨æ¨¡å¼
        for message in self.conversation_history:
            if message.get("role") == "assistant":
                content = message.get("content", "")
                # æ£€æŸ¥å¸¸è§çš„è®°å¿†æ“ä½œå…³é”®è¯
                if "retrieve" in content or "æŸ¥è¯¢" in content:
                    if "è¯­ä¹‰" in content or "semantic" in content: memories_used.append("semantic_memory")
                    if "æƒ…èŠ‚" in content or "episodic" in content: memories_used.append("episodic_memory") 
                    if "é•¿æœŸ" in content or "ltm" in content: memories_used.append("ltm_memory")
                    if "çŸ¥è¯†å›¾è°±" in content or "kg" in content: memories_used.append("knowledge_graph")
                    if "ç¨‹åºæ€§" in content or "procedural" in content: memories_used.append("procedural_memory")
                    if "å·¥ä½œ" in content or "wm" in content: memories_used.append("working_memory")
        
        return list(set(memories_used))  # å»é‡

    def _end_conversation(self) -> dict:
        logger.info("æ‰§è¡Œå·¥å…· [end_conversation]")
        self.conversation_history = [{"role": "system", "content": self._get_system_prompt()}]
        return {"status": "success", "message": "å¥½çš„ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨çš„é¡¹ç›®ç®¡ç†å·¥ä½œæä¾›æ”¯æŒã€‚"}

if __name__ == "__main__":
    setup_logging()
    logger.info("================== é¡¹ç›®ç®¡ç†Agentä¼šè¯å¼€å§‹ ==================")
    agent = ProjectManagementAgent(user_id=USER_ID, agent_id=AGENT_ID)
    agent.run()
    logger.info("================== é¡¹ç›®ç®¡ç†Agentä¼šè¯ç»“æŸ ==================")
